{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3bc755",
   "metadata": {},
   "source": [
    "# arXiv data subset - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a899c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dr = os.path.split(os.getcwd())[0]\n",
    "if parent_dr not in sys.path:\n",
    "    sys.path.append(parent_dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1372880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from core.data.arxiv_data_io import *\n",
    "from core.data.generate_tf_idf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ca1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185054bf",
   "metadata": {},
   "source": [
    "Pickle file can be found:\n",
    "https://drive.google.com/drive/folders/1CQx3y_9vWHt9Zi9aJWp9lK0W__9T7zTY?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882900b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"tokenized_arxiv_subset_15540.pkl\"\n",
    "full_path = os.path.join(parent_dr, \"core\", \"resources\", file_name)\n",
    "data_df = pd.read_pickle(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "285cb1bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>update_dt</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0648</td>\n",
       "      <td>Kaushik Majumdar</td>\n",
       "      <td>Behavioral response to strong aversive stimuli: A neurodynamical model</td>\n",
       "      <td>q-bio.NC</td>\n",
       "      <td>In this paper a theoretical model of functioning of a neural circuit during a\\nbehavioral response has been proposed. A neural circuit can be thought of as a\\ndirected multigraph whose each vertex is a neuron and each edge is a synapse.\\nIt has been assumed in this paper that the behavior of such circuits is\\nmanifested through the collective behavior of neurons belonging to that\\ncircuit. Behavioral information of each neuron is contained in the coefficients\\nof the fast Fourier transform (FFT) over the output spike train. Those\\ncoefficients form a vector in a multidimensional vector space. Behavioral\\ndynamics of a neuronal network in response to strong aversive stimuli has been\\nstudied in a vector space in which a suitable pseudometric has been defined.\\nThe neurodynamical model of network behavior has been formulated in terms of\\nexisting memory, synaptic plasticity and feelings. The model has an analogy in\\nclassical electrostatics, by which the notion of force and potential energy has\\nbeen introduced. Since the model takes input from each neuron in a network and\\nproduces a behavior as the output, it would be extremely difficult or may even\\nbe impossible to implement. But with the help of the model a possible\\nexplanation for an hitherto unexplained neurological observation in human brain\\nhas been offered. The model is compatible with a recent model of sequential\\nbehavioral dynamics. The model is based on electrophysiology, but its relevance\\nto hemodynamics has been outlined.\\n</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>in this paper a theoretical model of functioning of a neural circuit during a behavioral response has been proposed a neural circuit can be thought of as a directed multigraph whose each vertex is a neuron and each edge is a synapse it has been assumed in this paper that the behavior of such circuits is manifested through the collective behavior of neurons belonging to that circuit behavioral information of each neuron is contained in the coefficients of the fast fourier transform fft over the output spike train those coefficients form a vector in a multidimensional vector space behavioral dynamics of a neuronal network in response to strong aversive stimuli has been studied in a vector space in which a suitable pseudometric has been defined the neurodynamical model of network behavior has been formulated in terms of existing memory synaptic plasticity and feelings the model has an analogy in classical electrostatics by which the notion of force and potential energy has been introduced since the model takes input from each neuron in a network and produces a behavior as the output it would be extremely difficult or may even be impossible to implement but with the help of the model a possible explanation for an hitherto unexplained neurological observation in human brain has been offered the model is compatible with a recent model of sequential behavioral dynamics the model is based on electrophysiology but its relevance to hemodynamics has been outlined</td>\n",
       "      <td>[paper, theoretical, model, functioning, neural, circuit, behavioral, response, propose, neural, circuit, think, direct, multigraph, vertex, neuron, edge, synapse, assume, paper, behavior, circuit, manifest, collective, behavior, neuron, belong, circuit, behavioral, information, neuron, contain, coefficient, fast, fourier, transform, fft, output, spike, train, coefficient, form, vector, multidimensional, vector, space, behavioral, dynamic, neuronal, network, response, strong, aversive, stimulus, study, vector, space, suitable, pseudometric, define, neurodynamical, model, network, behavior, formulate, term, exist, memory, synaptic, plasticity, feeling, model, analogy, classical, electrostatic, notion, force, potential, energy, introduce, model, take, input, neuron, network, produce, behavior, output, extremely, difficult, impossible, implement, help, model, possible, explanation, hitherto, unexplained, neurological, observation, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.1394</td>\n",
       "      <td>Tarik Hadzic, Rune Moller Jensen, Henrik Reif Andersen</td>\n",
       "      <td>Calculating Valid Domains for BDD-Based Interactive Configuration</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>In these notes we formally describe the functionality of Calculating Valid\\nDomains from the BDD representing the solution space of valid configurations.\\nThe formalization is largely based on the CLab configuration framework.\\n</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>in these notes we formally describe the functionality of calculating valid domains from the bdd representing the solution space of valid configurations the formalization is largely based on the clab configuration framework</td>\n",
       "      <td>[note, formally, describe, functionality, calculate, valid, domain, bdd, represent, solution, space, valid, configuration, formalization, largely, base, clab, configuration, framework]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.1829</td>\n",
       "      <td>Stefan Felsner, Kamil Kloch, Grzegorz Matecki, and Piotr Micek</td>\n",
       "      <td>On-line Chain Partitions of Up-growing Semi-orders</td>\n",
       "      <td>cs.DM</td>\n",
       "      <td>On-line chain partition is a two-player game between Spoiler and Algorithm.\\nSpoiler presents a partially ordered set, point by point. Algorithm assigns\\nincoming points (immediately and irrevocably) to the chains which constitute a\\nchain partition of the order. The value of the game for orders of width $w$ is\\na minimum number $\\fVal(w)$ such that Algorithm has a strategy using at most\\n$\\fVal(w)$ chains on orders of width at most $w$. We analyze the chain\\npartition game for up-growing semi-orders. Surprisingly, the golden ratio comes\\ninto play and the value of the game is $\\lfloor\\frac{1+\\sqrt{5}}{2}\\; w\\n\\rfloor$.\\n</td>\n",
       "      <td>2011-02-22</td>\n",
       "      <td>on line chain partition is a two player game between spoiler and algorithm spoiler presents a partially ordered set point by point algorithm assigns incoming points immediately and irrevocably to the chains which constitute a chain partition of the order the value of the game for orders of width w is a minimum number fval w such that algorithm has a strategy using at most fval w chains on orders of width at most w we analyze the chain partition game for up growing semi orders surprisingly the golden ratio comes into play and the value of the game is lfloor frac number sqrt number number w rfloor</td>\n",
       "      <td>[line, chain, partition, player, game, spoiler, algorithm, spoiler, present, partially, order, set, point, point, algorithm, assign, incoming, point, immediately, irrevocably, chain, constitute, chain, partition, order, value, game, order, width, minimum, number, fval, algorithm, strategy, fval, chain, order, width, analyze, chain, partition, game, grow, semi, order, surprisingly, golden, ratio, come, play, value, game, lfloor, frac, number, sqrt, number, number, rfloor]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                                         authors  \\\n",
       "0  0704.0648                                                Kaushik Majumdar   \n",
       "1  0704.1394          Tarik Hadzic, Rune Moller Jensen, Henrik Reif Andersen   \n",
       "2  0704.1829  Stefan Felsner, Kamil Kloch, Grzegorz Matecki, and Piotr Micek   \n",
       "\n",
       "                                                                    title  \\\n",
       "0  Behavioral response to strong aversive stimuli: A neurodynamical model   \n",
       "1       Calculating Valid Domains for BDD-Based Interactive Configuration   \n",
       "2                      On-line Chain Partitions of Up-growing Semi-orders   \n",
       "\n",
       "  categories  \\\n",
       "0   q-bio.NC   \n",
       "1      cs.AI   \n",
       "2      cs.DM   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        abstract  \\\n",
       "0    In this paper a theoretical model of functioning of a neural circuit during a\\nbehavioral response has been proposed. A neural circuit can be thought of as a\\ndirected multigraph whose each vertex is a neuron and each edge is a synapse.\\nIt has been assumed in this paper that the behavior of such circuits is\\nmanifested through the collective behavior of neurons belonging to that\\ncircuit. Behavioral information of each neuron is contained in the coefficients\\nof the fast Fourier transform (FFT) over the output spike train. Those\\ncoefficients form a vector in a multidimensional vector space. Behavioral\\ndynamics of a neuronal network in response to strong aversive stimuli has been\\nstudied in a vector space in which a suitable pseudometric has been defined.\\nThe neurodynamical model of network behavior has been formulated in terms of\\nexisting memory, synaptic plasticity and feelings. The model has an analogy in\\nclassical electrostatics, by which the notion of force and potential energy has\\nbeen introduced. Since the model takes input from each neuron in a network and\\nproduces a behavior as the output, it would be extremely difficult or may even\\nbe impossible to implement. But with the help of the model a possible\\nexplanation for an hitherto unexplained neurological observation in human brain\\nhas been offered. The model is compatible with a recent model of sequential\\nbehavioral dynamics. The model is based on electrophysiology, but its relevance\\nto hemodynamics has been outlined.\\n   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           In these notes we formally describe the functionality of Calculating Valid\\nDomains from the BDD representing the solution space of valid configurations.\\nThe formalization is largely based on the CLab configuration framework.\\n   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          On-line chain partition is a two-player game between Spoiler and Algorithm.\\nSpoiler presents a partially ordered set, point by point. Algorithm assigns\\nincoming points (immediately and irrevocably) to the chains which constitute a\\nchain partition of the order. The value of the game for orders of width $w$ is\\na minimum number $\\fVal(w)$ such that Algorithm has a strategy using at most\\n$\\fVal(w)$ chains on orders of width at most $w$. We analyze the chain\\npartition game for up-growing semi-orders. Surprisingly, the golden ratio comes\\ninto play and the value of the game is $\\lfloor\\frac{1+\\sqrt{5}}{2}\\; w\\n\\rfloor$.\\n   \n",
       "\n",
       "    update_dt  \\\n",
       "0  2007-05-23   \n",
       "1  2007-05-23   \n",
       "2  2011-02-22   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  clean  \\\n",
       "0  in this paper a theoretical model of functioning of a neural circuit during a behavioral response has been proposed a neural circuit can be thought of as a directed multigraph whose each vertex is a neuron and each edge is a synapse it has been assumed in this paper that the behavior of such circuits is manifested through the collective behavior of neurons belonging to that circuit behavioral information of each neuron is contained in the coefficients of the fast fourier transform fft over the output spike train those coefficients form a vector in a multidimensional vector space behavioral dynamics of a neuronal network in response to strong aversive stimuli has been studied in a vector space in which a suitable pseudometric has been defined the neurodynamical model of network behavior has been formulated in terms of existing memory synaptic plasticity and feelings the model has an analogy in classical electrostatics by which the notion of force and potential energy has been introduced since the model takes input from each neuron in a network and produces a behavior as the output it would be extremely difficult or may even be impossible to implement but with the help of the model a possible explanation for an hitherto unexplained neurological observation in human brain has been offered the model is compatible with a recent model of sequential behavioral dynamics the model is based on electrophysiology but its relevance to hemodynamics has been outlined   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        in these notes we formally describe the functionality of calculating valid domains from the bdd representing the solution space of valid configurations the formalization is largely based on the clab configuration framework   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            on line chain partition is a two player game between spoiler and algorithm spoiler presents a partially ordered set point by point algorithm assigns incoming points immediately and irrevocably to the chains which constitute a chain partition of the order the value of the game for orders of width w is a minimum number fval w such that algorithm has a strategy using at most fval w chains on orders of width at most w we analyze the chain partition game for up growing semi orders surprisingly the golden ratio comes into play and the value of the game is lfloor frac number sqrt number number w rfloor   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               tokens  \n",
       "0  [paper, theoretical, model, functioning, neural, circuit, behavioral, response, propose, neural, circuit, think, direct, multigraph, vertex, neuron, edge, synapse, assume, paper, behavior, circuit, manifest, collective, behavior, neuron, belong, circuit, behavioral, information, neuron, contain, coefficient, fast, fourier, transform, fft, output, spike, train, coefficient, form, vector, multidimensional, vector, space, behavioral, dynamic, neuronal, network, response, strong, aversive, stimulus, study, vector, space, suitable, pseudometric, define, neurodynamical, model, network, behavior, formulate, term, exist, memory, synaptic, plasticity, feeling, model, analogy, classical, electrostatic, notion, force, potential, energy, introduce, model, take, input, neuron, network, produce, behavior, output, extremely, difficult, impossible, implement, help, model, possible, explanation, hitherto, unexplained, neurological, observation, ...]  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [note, formally, describe, functionality, calculate, valid, domain, bdd, represent, solution, space, valid, configuration, formalization, largely, base, clab, configuration, framework]  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [line, chain, partition, player, game, spoiler, algorithm, spoiler, present, partially, order, set, point, point, algorithm, assign, incoming, point, immediately, irrevocably, chain, constitute, chain, partition, order, value, game, order, width, minimum, number, fval, algorithm, strategy, fval, chain, order, width, analyze, chain, partition, game, grow, semi, order, surprisingly, golden, ratio, come, play, value, game, lfloor, frac, number, sqrt, number, number, rfloor]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dfc28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, _ = sample_arxiv_data_by_category(data_df)\n",
    "assert len(train_df)/len(data_df) == 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2943101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>update_dt</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>full_df_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0803.0159</td>\n",
       "      <td>V.R. Vemula, David Ball, Simon Thorne</td>\n",
       "      <td>Towards a Spreadsheet Engineering</td>\n",
       "      <td>cs.CY</td>\n",
       "      <td>In this paper, we report some on-going focused research, but are further keen\\nto set it in the context of a proposed bigger picture, as follows. There is a\\ncertain depressing pattern about the attitude of industry to spreadsheet error\\nresearch and a certain pattern about conferences highlighting these issues. Is\\nit not high time to move on from measuring spreadsheet errors to developing an\\narmoury of disciplines and controls? In short, we propose the need to\\nrigorously lay the foundations of a spreadsheet engineering discipline.\\nClearly, multiple research teams would be required to tackle such a big task.\\nThis suggests the need for both national and international collaborative\\nresearch, since any given group can only address a small segment of the whole.\\nThere are already a small number of examples of such on-going international\\ncollaborative research. Having established the need for a directed research\\neffort, the rest of the paper then attempts to act as an exemplar in\\ndemonstrating and applying this focus. With regard to one such of research, in\\na recent paper, Panko (2005) stated that: \"...group development and testing\\nappear to be promising areas to pursue\". Of particular interest to us are some\\ngaps in the published research record on techniques to reduce errors. We\\nfurther report on the topics: techniques for cross-checking, time constraints\\neffects, and some aspects of developer perception.\\n</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>in this paper we report some on going focused research but are further keen to set it in the context of a proposed bigger picture as follows there is a certain depressing pattern about the attitude of industry to spreadsheet error research and a certain pattern about conferences highlighting these issues is it not high time to move on from measuring spreadsheet errors to developing an armoury of disciplines and controls in short we propose the need to rigorously lay the foundations of a spreadsheet engineering discipline clearly multiple research teams would be required to tackle such a big task this suggests the need for both national and international collaborative research since any given group can only address a small segment of the whole there are already a small number of examples of such on going international collaborative research having established the need for a directed research effort the rest of the paper then attempts to act as an exemplar in demonstrating and applying this focus with regard to one such of research in a recent paper panko number stated that group development and testing appear to be promising areas to pursue of particular interest to us are some gaps in the published research record on techniques to reduce errors we further report on the topics techniques for cross checking time constraints effects and some aspects of developer perception</td>\n",
       "      <td>[paper, report, go, focus, research, keen, set, context, propose, big, picture, follow, certain, depressing, pattern, attitude, industry, spreadsheet, error, research, certain, pattern, conference, highlight, issue, high, time, measure, spreadsheet, error, develop, armoury, discipline, control, short, propose, need, rigorously, lay, foundation, spreadsheet, engineering, discipline, clearly, multiple, research, team, require, tackle, big, task, suggest, need, national, international, collaborative, research, give, group, address, small, segment, small, number, example, go, international, collaborative, research, have, establish, need, direct, research, effort, rest, paper, attempt, act, exemplar, demonstrate, apply, focus, regard, research, recent, paper, panko, number, state, group, development, testing, appear, promise, area, pursue, particular, interest, gap, ...]</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1109.4554</td>\n",
       "      <td>Paul Bonsma</td>\n",
       "      <td>Surface Split Decompositions and Subgraph Isomorphism in Graphs on\\n  Surfaces</td>\n",
       "      <td>cs.DM</td>\n",
       "      <td>The Subgraph Isomorphism problem asks, given a host graph G on n vertices and\\na pattern graph P on k vertices, whether G contains a subgraph isomorphic to P.\\nThe restriction of this problem to planar graphs has often been considered.\\nAfter a sequence of improvements, the current best algorithm for planar graphs\\nis a linear time algorithm by Dorn (STACS '10), with complexity $2^{O(k)}\\nO(n)$.\\n  We generalize this result, by giving an algorithm of the same complexity for\\ngraphs that can be embedded in surfaces of bounded genus. At the same time, we\\nsimplify the algorithm and analysis. The key to these improvements is the\\nintroduction of surface split decompositions for bounded genus graphs, which\\ngeneralize sphere cut decompositions for planar graphs. We extend the algorithm\\nfor the problem of counting and generating all subgraphs isomorphic to P, even\\nfor the case where P is disconnected. This answers an open question by Eppstein\\n(SODA '95 / JGAA '99).\\n</td>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>the subgraph isomorphism problem asks given a host graph g on n vertices and a pattern graph p on k vertices whether g contains a subgraph isomorphic to p the restriction of this problem to planar graphs has often been considered after a sequence of improvements the current best algorithm for planar graphs is a linear time algorithm by dorn stacs number with complexity number o k o n we generalize this result by giving an algorithm of the same complexity for graphs that can be embedded in surfaces of bounded genus at the same time we simplify the algorithm and analysis the key to these improvements is the introduction of surface split decompositions for bounded genus graphs which generalize sphere cut decompositions for planar graphs we extend the algorithm for the problem of counting and generating all subgraphs isomorphic to p even for the case where p is disconnected this answers an open question by eppstein soda number jgaa number</td>\n",
       "      <td>[subgraph, isomorphism, problem, ask, give, host, graph, vertex, pattern, graph, vertex, contain, subgraph, isomorphic, restriction, problem, planar, graph, consider, sequence, improvement, current, good, algorithm, planar, graph, linear, time, algorithm, dorn, stac, number, complexity, number, generalize, result, give, algorithm, complexity, graph, embed, surface, bounded, genus, time, simplify, algorithm, analysis, key, improvement, introduction, surface, split, decomposition, bounded, genus, graph, generalize, sphere, cut, decomposition, planar, graph, extend, algorithm, problem, count, generate, subgraphs, isomorphic, case, disconnect, answer, open, question, eppstein, soda, number, jgaa, number]</td>\n",
       "      <td>1417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1104.3250</td>\n",
       "      <td>Salah Rifai, Xavier Glorot, Yoshua Bengio, Pascal Vincent</td>\n",
       "      <td>Adding noise to the input of a model trained with a regularized\\n  objective</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>Regularization is a well studied problem in the context of neural networks.\\nIt is usually used to improve the generalization performance when the number of\\ninput samples is relatively small or heavily contaminated with noise. The\\nregularization of a parametric model can be achieved in different manners some\\nof which are early stopping (Morgan and Bourlard, 1990), weight decay, output\\nsmoothing that are used to avoid overfitting during the training of the\\nconsidered model. From a Bayesian point of view, many regularization techniques\\ncorrespond to imposing certain prior distributions on model parameters (Krogh\\nand Hertz, 1991). Using Bishop's approximation (Bishop, 1995) of the objective\\nfunction when a restricted type of noise is added to the input of a parametric\\nfunction, we derive the higher order terms of the Taylor expansion and analyze\\nthe coefficients of the regularization terms induced by the noisy input. In\\nparticular we study the effect of penalizing the Hessian of the mapping\\nfunction with respect to the input in terms of generalization performance. We\\nalso show how we can control independently this coefficient by explicitly\\npenalizing the Jacobian of the mapping function on corrupted inputs.\\n</td>\n",
       "      <td>2011-04-19</td>\n",
       "      <td>regularization is a well studied problem in the context of neural networks it is usually used to improve the generalization performance when the number of input samples is relatively small or heavily contaminated with noise the regularization of a parametric model can be achieved in different manners some of which are early stopping morgan and bourlard number weight decay output smoothing that are used to avoid overfitting during the training of the considered model from a bayesian point of view many regularization techniques correspond to imposing certain prior distributions on model parameters krogh and hertz number using bishop s approximation bishop number of the objective function when a restricted type of noise is added to the input of a parametric function we derive the higher order terms of the taylor expansion and analyze the coefficients of the regularization terms induced by the noisy input in particular we study the effect of penalizing the hessian of the mapping function with respect to the input in terms of generalization performance we also show how we can control independently this coefficient by explicitly penalizing the jacobian of the mapping function on corrupted inputs</td>\n",
       "      <td>[regularization, study, problem, context, neural, network, usually, improve, generalization, performance, number, input, sample, relatively, small, heavily, contaminate, noise, regularization, parametric, model, achieve, different, manner, early, stop, morgan, bourlard, number, weight, decay, output, smoothing, avoid, overfitting, training, considered, model, bayesian, point, view, regularization, technique, correspond, impose, certain, prior, distribution, model, parameter, krogh, hertz, number, bishop, approximation, bishop, number, objective, function, restricted, type, noise, add, input, parametric, function, derive, high, order, term, taylor, expansion, analyze, coefficient, regularization, term, induce, noisy, input, particular, study, effect, penalize, hessian, mapping, function, respect, input, term, generalization, performance, control, independently, coefficient, explicitly, penalize, jacobian, mapping, function, corrupted, ...]</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1502.04240</td>\n",
       "      <td>H. Furma\\'nczyk, M. Kubale</td>\n",
       "      <td>Scheduling of unit-length jobs with cubic incompatibility graphs on\\n  three uniform machines</td>\n",
       "      <td>cs.DM</td>\n",
       "      <td>In the paper we consider the problem of scheduling $n$ identical jobs on 3\\nuniform machines with speeds $s_1, s_2,$ and $s_3$ to minimize the schedule\\nlength. We assume that jobs are subjected to some kind of mutual exclusion\\nconstraints, modeled by a cubic incompatibility graph. We show that if the\\ngraph is 2-chromatic then the problem can be solved in $O(n^2)$ time. If the\\ngraph is 3-chromatic, the problem becomes NP-hard even if $s_1&gt;s_2=s_3$.\\nHowever, in this case there exists a $4/3$-approximation algorithm running in\\n$O(n^3)$ time. Moreover, this algorithm solves the problem almost surely to\\noptimality if $3s_1/4 \\leq s_2 = s_3$.\\n</td>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>in the paper we consider the problem of scheduling n identical jobs on number uniform machines with speeds s_number s_number and s_number to minimize the schedule length we assume that jobs are subjected to some kind of mutual exclusion constraints modeled by a cubic incompatibility graph we show that if the graph is number chromatic then the problem can be solved in o n number time if the graph is number chromatic the problem becomes np hard even if s_number s_number s_number however in this case there exists a number number approximation algorithm running in o n number time moreover this algorithm solves the problem almost surely to optimality if numbers_number number leq s_number s_number</td>\n",
       "      <td>[paper, consider, problem, scheduling, identical, job, number, uniform, machine, speed, minimize, schedule, length, assume, job, subject, kind, mutual, exclusion, constraint, model, cubic, incompatibility, graph, graph, number, chromatic, problem, solve, number, time, graph, number, chromatic, problem, np, hard, case, exist, number, number, approximation, algorithm, run, number, time, algorithm, solve, problem, surely, optimality, number, leq]</td>\n",
       "      <td>4652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003.00749</td>\n",
       "      <td>David Tuckey, Alessandra Russo, Krysia Broda</td>\n",
       "      <td>A general framework for scientifically inspired explanations in AI</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>Explainability in AI is gaining attention in the computer science community\\nin response to the increasing success of deep learning and the important need\\nof justifying how such systems make predictions in life-critical applications.\\nThe focus of explainability in AI has predominantly been on trying to gain\\ninsights into how machine learning systems function by exploring relationships\\nbetween input data and predicted outcomes or by extracting simpler\\ninterpretable models. Through literature surveys of philosophy and social\\nscience, authors have highlighted the sharp difference between these generated\\nexplanations and human-made explanations and claimed that current explanations\\nin AI do not take into account the complexity of human interaction to allow for\\neffective information passing to not-expert users. In this paper we instantiate\\nthe concept of structure of scientific explanation as the theoretical\\nunderpinning for a general framework in which explanations for AI systems can\\nbe implemented. This framework aims to provide the tools to build a\\n\"mental-model\" of any AI system so that the interaction with the user can\\nprovide information on demand and be closer to the nature of human-made\\nexplanations. We illustrate how we can utilize this framework through two very\\ndifferent examples: an artificial neural network and a Prolog solver and we\\nprovide a possible implementation for both examples.\\n</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>explainability in ai is gaining attention in the computer science community in response to the increasing success of deep learning and the important need of justifying how such systems make predictions in life critical applications the focus of explainability in ai has predominantly been on trying to gain insights into how machine learning systems function by exploring relationships between input data and predicted outcomes or by extracting simpler interpretable models through literature surveys of philosophy and social science authors have highlighted the sharp difference between these generated explanations and human made explanations and claimed that current explanations in ai do not take into account the complexity of human interaction to allow for effective information passing to not expert users in this paper we instantiate the concept of structure of scientific explanation as the theoretical underpinning for a general framework in which explanations for ai systems can be implemented this framework aims to provide the tools to build a mental model of any ai system so that the interaction with the user can provide information on demand and be closer to the nature of human made explanations we illustrate how we can utilize this framework through two very different examples an artificial neural network and a prolog solver and we provide a possible implementation for both examples</td>\n",
       "      <td>[explainability, ai, gain, attention, computer, science, community, response, increase, success, deep, learning, important, need, justify, system, prediction, life, critical, application, focus, explainability, ai, predominantly, try, gain, insight, machine, learn, system, function, explore, relationship, input, datum, predict, outcome, extract, simple, interpretable, model, literature, survey, philosophy, social, science, author, highlight, sharp, difference, generate, explanation, human, explanation, claim, current, explanation, ai, account, complexity, human, interaction, allow, effective, information, pass, expert, user, paper, instantiate, concept, structure, scientific, explanation, theoretical, underpinning, general, framework, explanation, ai, system, implement, framework, aim, provide, tool, build, mental, model, ai, system, interaction, user, provide, information, demand, close, nature, human, explanation, ...]</td>\n",
       "      <td>11107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                                    authors  \\\n",
       "0   0803.0159                      V.R. Vemula, David Ball, Simon Thorne   \n",
       "1   1109.4554                                                Paul Bonsma   \n",
       "2   1104.3250  Salah Rifai, Xavier Glorot, Yoshua Bengio, Pascal Vincent   \n",
       "3  1502.04240                                 H. Furma\\'nczyk, M. Kubale   \n",
       "4  2003.00749               David Tuckey, Alessandra Russo, Krysia Broda   \n",
       "\n",
       "                                                                                           title  \\\n",
       "0                                                              Towards a Spreadsheet Engineering   \n",
       "1                 Surface Split Decompositions and Subgraph Isomorphism in Graphs on\\n  Surfaces   \n",
       "2                   Adding noise to the input of a model trained with a regularized\\n  objective   \n",
       "3  Scheduling of unit-length jobs with cubic incompatibility graphs on\\n  three uniform machines   \n",
       "4                             A general framework for scientifically inspired explanations in AI   \n",
       "\n",
       "  categories  \\\n",
       "0      cs.CY   \n",
       "1      cs.DM   \n",
       "2      cs.AI   \n",
       "3      cs.DM   \n",
       "4      cs.AI   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              abstract  \\\n",
       "0    In this paper, we report some on-going focused research, but are further keen\\nto set it in the context of a proposed bigger picture, as follows. There is a\\ncertain depressing pattern about the attitude of industry to spreadsheet error\\nresearch and a certain pattern about conferences highlighting these issues. Is\\nit not high time to move on from measuring spreadsheet errors to developing an\\narmoury of disciplines and controls? In short, we propose the need to\\nrigorously lay the foundations of a spreadsheet engineering discipline.\\nClearly, multiple research teams would be required to tackle such a big task.\\nThis suggests the need for both national and international collaborative\\nresearch, since any given group can only address a small segment of the whole.\\nThere are already a small number of examples of such on-going international\\ncollaborative research. Having established the need for a directed research\\neffort, the rest of the paper then attempts to act as an exemplar in\\ndemonstrating and applying this focus. With regard to one such of research, in\\na recent paper, Panko (2005) stated that: \"...group development and testing\\nappear to be promising areas to pursue\". Of particular interest to us are some\\ngaps in the published research record on techniques to reduce errors. We\\nfurther report on the topics: techniques for cross-checking, time constraints\\neffects, and some aspects of developer perception.\\n   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The Subgraph Isomorphism problem asks, given a host graph G on n vertices and\\na pattern graph P on k vertices, whether G contains a subgraph isomorphic to P.\\nThe restriction of this problem to planar graphs has often been considered.\\nAfter a sequence of improvements, the current best algorithm for planar graphs\\nis a linear time algorithm by Dorn (STACS '10), with complexity $2^{O(k)}\\nO(n)$.\\n  We generalize this result, by giving an algorithm of the same complexity for\\ngraphs that can be embedded in surfaces of bounded genus. At the same time, we\\nsimplify the algorithm and analysis. The key to these improvements is the\\nintroduction of surface split decompositions for bounded genus graphs, which\\ngeneralize sphere cut decompositions for planar graphs. We extend the algorithm\\nfor the problem of counting and generating all subgraphs isomorphic to P, even\\nfor the case where P is disconnected. This answers an open question by Eppstein\\n(SODA '95 / JGAA '99).\\n   \n",
       "2                                                                                                                                                                                                              Regularization is a well studied problem in the context of neural networks.\\nIt is usually used to improve the generalization performance when the number of\\ninput samples is relatively small or heavily contaminated with noise. The\\nregularization of a parametric model can be achieved in different manners some\\nof which are early stopping (Morgan and Bourlard, 1990), weight decay, output\\nsmoothing that are used to avoid overfitting during the training of the\\nconsidered model. From a Bayesian point of view, many regularization techniques\\ncorrespond to imposing certain prior distributions on model parameters (Krogh\\nand Hertz, 1991). Using Bishop's approximation (Bishop, 1995) of the objective\\nfunction when a restricted type of noise is added to the input of a parametric\\nfunction, we derive the higher order terms of the Taylor expansion and analyze\\nthe coefficients of the regularization terms induced by the noisy input. In\\nparticular we study the effect of penalizing the Hessian of the mapping\\nfunction with respect to the input in terms of generalization performance. We\\nalso show how we can control independently this coefficient by explicitly\\npenalizing the Jacobian of the mapping function on corrupted inputs.\\n   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        In the paper we consider the problem of scheduling $n$ identical jobs on 3\\nuniform machines with speeds $s_1, s_2,$ and $s_3$ to minimize the schedule\\nlength. We assume that jobs are subjected to some kind of mutual exclusion\\nconstraints, modeled by a cubic incompatibility graph. We show that if the\\ngraph is 2-chromatic then the problem can be solved in $O(n^2)$ time. If the\\ngraph is 3-chromatic, the problem becomes NP-hard even if $s_1>s_2=s_3$.\\nHowever, in this case there exists a $4/3$-approximation algorithm running in\\n$O(n^3)$ time. Moreover, this algorithm solves the problem almost surely to\\noptimality if $3s_1/4 \\leq s_2 = s_3$.\\n   \n",
       "4          Explainability in AI is gaining attention in the computer science community\\nin response to the increasing success of deep learning and the important need\\nof justifying how such systems make predictions in life-critical applications.\\nThe focus of explainability in AI has predominantly been on trying to gain\\ninsights into how machine learning systems function by exploring relationships\\nbetween input data and predicted outcomes or by extracting simpler\\ninterpretable models. Through literature surveys of philosophy and social\\nscience, authors have highlighted the sharp difference between these generated\\nexplanations and human-made explanations and claimed that current explanations\\nin AI do not take into account the complexity of human interaction to allow for\\neffective information passing to not-expert users. In this paper we instantiate\\nthe concept of structure of scientific explanation as the theoretical\\nunderpinning for a general framework in which explanations for AI systems can\\nbe implemented. This framework aims to provide the tools to build a\\n\"mental-model\" of any AI system so that the interaction with the user can\\nprovide information on demand and be closer to the nature of human-made\\nexplanations. We illustrate how we can utilize this framework through two very\\ndifferent examples: an artificial neural network and a Prolog solver and we\\nprovide a possible implementation for both examples.\\n   \n",
       "\n",
       "    update_dt  \\\n",
       "0  2008-03-10   \n",
       "1  2015-03-19   \n",
       "2  2011-04-19   \n",
       "3  2015-06-17   \n",
       "4  2020-03-03   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           clean  \\\n",
       "0               in this paper we report some on going focused research but are further keen to set it in the context of a proposed bigger picture as follows there is a certain depressing pattern about the attitude of industry to spreadsheet error research and a certain pattern about conferences highlighting these issues is it not high time to move on from measuring spreadsheet errors to developing an armoury of disciplines and controls in short we propose the need to rigorously lay the foundations of a spreadsheet engineering discipline clearly multiple research teams would be required to tackle such a big task this suggests the need for both national and international collaborative research since any given group can only address a small segment of the whole there are already a small number of examples of such on going international collaborative research having established the need for a directed research effort the rest of the paper then attempts to act as an exemplar in demonstrating and applying this focus with regard to one such of research in a recent paper panko number stated that group development and testing appear to be promising areas to pursue of particular interest to us are some gaps in the published research record on techniques to reduce errors we further report on the topics techniques for cross checking time constraints effects and some aspects of developer perception   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                           the subgraph isomorphism problem asks given a host graph g on n vertices and a pattern graph p on k vertices whether g contains a subgraph isomorphic to p the restriction of this problem to planar graphs has often been considered after a sequence of improvements the current best algorithm for planar graphs is a linear time algorithm by dorn stacs number with complexity number o k o n we generalize this result by giving an algorithm of the same complexity for graphs that can be embedded in surfaces of bounded genus at the same time we simplify the algorithm and analysis the key to these improvements is the introduction of surface split decompositions for bounded genus graphs which generalize sphere cut decompositions for planar graphs we extend the algorithm for the problem of counting and generating all subgraphs isomorphic to p even for the case where p is disconnected this answers an open question by eppstein soda number jgaa number   \n",
       "2                                                                                                                                                                                                       regularization is a well studied problem in the context of neural networks it is usually used to improve the generalization performance when the number of input samples is relatively small or heavily contaminated with noise the regularization of a parametric model can be achieved in different manners some of which are early stopping morgan and bourlard number weight decay output smoothing that are used to avoid overfitting during the training of the considered model from a bayesian point of view many regularization techniques correspond to imposing certain prior distributions on model parameters krogh and hertz number using bishop s approximation bishop number of the objective function when a restricted type of noise is added to the input of a parametric function we derive the higher order terms of the taylor expansion and analyze the coefficients of the regularization terms induced by the noisy input in particular we study the effect of penalizing the hessian of the mapping function with respect to the input in terms of generalization performance we also show how we can control independently this coefficient by explicitly penalizing the jacobian of the mapping function on corrupted inputs   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   in the paper we consider the problem of scheduling n identical jobs on number uniform machines with speeds s_number s_number and s_number to minimize the schedule length we assume that jobs are subjected to some kind of mutual exclusion constraints modeled by a cubic incompatibility graph we show that if the graph is number chromatic then the problem can be solved in o n number time if the graph is number chromatic the problem becomes np hard even if s_number s_number s_number however in this case there exists a number number approximation algorithm running in o n number time moreover this algorithm solves the problem almost surely to optimality if numbers_number number leq s_number s_number   \n",
       "4  explainability in ai is gaining attention in the computer science community in response to the increasing success of deep learning and the important need of justifying how such systems make predictions in life critical applications the focus of explainability in ai has predominantly been on trying to gain insights into how machine learning systems function by exploring relationships between input data and predicted outcomes or by extracting simpler interpretable models through literature surveys of philosophy and social science authors have highlighted the sharp difference between these generated explanations and human made explanations and claimed that current explanations in ai do not take into account the complexity of human interaction to allow for effective information passing to not expert users in this paper we instantiate the concept of structure of scientific explanation as the theoretical underpinning for a general framework in which explanations for ai systems can be implemented this framework aims to provide the tools to build a mental model of any ai system so that the interaction with the user can provide information on demand and be closer to the nature of human made explanations we illustrate how we can utilize this framework through two very different examples an artificial neural network and a prolog solver and we provide a possible implementation for both examples   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     tokens  \\\n",
       "0                                                                            [paper, report, go, focus, research, keen, set, context, propose, big, picture, follow, certain, depressing, pattern, attitude, industry, spreadsheet, error, research, certain, pattern, conference, highlight, issue, high, time, measure, spreadsheet, error, develop, armoury, discipline, control, short, propose, need, rigorously, lay, foundation, spreadsheet, engineering, discipline, clearly, multiple, research, team, require, tackle, big, task, suggest, need, national, international, collaborative, research, give, group, address, small, segment, small, number, example, go, international, collaborative, research, have, establish, need, direct, research, effort, rest, paper, attempt, act, exemplar, demonstrate, apply, focus, regard, research, recent, paper, panko, number, state, group, development, testing, appear, promise, area, pursue, particular, interest, gap, ...]   \n",
       "1                                                                                                                                                                                                                                                     [subgraph, isomorphism, problem, ask, give, host, graph, vertex, pattern, graph, vertex, contain, subgraph, isomorphic, restriction, problem, planar, graph, consider, sequence, improvement, current, good, algorithm, planar, graph, linear, time, algorithm, dorn, stac, number, complexity, number, generalize, result, give, algorithm, complexity, graph, embed, surface, bounded, genus, time, simplify, algorithm, analysis, key, improvement, introduction, surface, split, decomposition, bounded, genus, graph, generalize, sphere, cut, decomposition, planar, graph, extend, algorithm, problem, count, generate, subgraphs, isomorphic, case, disconnect, answer, open, question, eppstein, soda, number, jgaa, number]   \n",
       "2  [regularization, study, problem, context, neural, network, usually, improve, generalization, performance, number, input, sample, relatively, small, heavily, contaminate, noise, regularization, parametric, model, achieve, different, manner, early, stop, morgan, bourlard, number, weight, decay, output, smoothing, avoid, overfitting, training, considered, model, bayesian, point, view, regularization, technique, correspond, impose, certain, prior, distribution, model, parameter, krogh, hertz, number, bishop, approximation, bishop, number, objective, function, restricted, type, noise, add, input, parametric, function, derive, high, order, term, taylor, expansion, analyze, coefficient, regularization, term, induce, noisy, input, particular, study, effect, penalize, hessian, mapping, function, respect, input, term, generalization, performance, control, independently, coefficient, explicitly, penalize, jacobian, mapping, function, corrupted, ...]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [paper, consider, problem, scheduling, identical, job, number, uniform, machine, speed, minimize, schedule, length, assume, job, subject, kind, mutual, exclusion, constraint, model, cubic, incompatibility, graph, graph, number, chromatic, problem, solve, number, time, graph, number, chromatic, problem, np, hard, case, exist, number, number, approximation, algorithm, run, number, time, algorithm, solve, problem, surely, optimality, number, leq]   \n",
       "4                    [explainability, ai, gain, attention, computer, science, community, response, increase, success, deep, learning, important, need, justify, system, prediction, life, critical, application, focus, explainability, ai, predominantly, try, gain, insight, machine, learn, system, function, explore, relationship, input, datum, predict, outcome, extract, simple, interpretable, model, literature, survey, philosophy, social, science, author, highlight, sharp, difference, generate, explanation, human, explanation, claim, current, explanation, ai, account, complexity, human, interaction, allow, effective, information, pass, expert, user, paper, instantiate, concept, structure, scientific, explanation, theoretical, underpinning, general, framework, explanation, ai, system, implement, framework, aim, provide, tool, build, mental, model, ai, system, interaction, user, provide, information, demand, close, nature, human, explanation, ...]   \n",
       "\n",
       "   full_df_index  \n",
       "0            184  \n",
       "1           1417  \n",
       "2           1083  \n",
       "3           4652  \n",
       "4          11107  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add602ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15540, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['id', 'authors', 'title', 'categories', 'abstract', 'update_dt',\n",
       "       'clean', 'tokens', 'full_df_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_df.shape)\n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2e779",
   "metadata": {},
   "source": [
    "## Create a tfidf vectorizer with dummy tokenizer\n",
    "### We've already tokenized and saved the results, so don't do it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95347edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_tokenizer(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_tokenizer,\n",
    "    preprocessor=dummy_tokenizer,\n",
    "    token_pattern=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e09e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(preprocessor=<function dummy_tokenizer at 0x168572040>,\n",
       "                token_pattern=None,\n",
       "                tokenizer=<function dummy_tokenizer at 0x168572040>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(train_df[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d28faa6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size for corpus:  30460\n"
     ]
    }
   ],
   "source": [
    "print(\"vocab size for corpus: \", len(tfidf.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d692e423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('paper', 19716), ('report', 23033), ('go', 11034), ('focus', 10078), ('research', 23106), ('keen', 14375), ('set', 24549), ('context', 5341), ('propose', 21656), ('big', 2642), ('picture', 20526), ('follow', 10108), ('certain', 3965), ('depressing', 6800), ('pattern', 19940), ('attitude', 1868), ('industry', 13090), ('spreadsheet', 25634), ('error', 8950), ('conference', 5108), ('highlight', 11884), ('issue', 13965), ('high', 11879), ('time', 27456), ('measure', 16221), ('develop', 6947), ('armoury', 1572), ('discipline', 7269), ('control', 5400), ('short', 24729), ('need', 17869), ('rigorously', 23464), ('lay', 14849), ('foundation', 10248), ('engineering', 8649), ('clearly', 4393), ('multiple', 17498), ('team', 27001), ('require', 23083), ('tackle', 26807), ('task', 26922), ('suggest', 26371), ('national', 17775), ('international', 13577), ('collaborative', 4675), ('give', 10922), ('group', 11289), ('address', 336), ('small', 25108), ('segment', 24348), ('number', 18589), ('example', 9188), ('have', 11605), ('establish', 9007), ('direct', 7201), ('effort', 8216), ('rest', 23199), ('attempt', 1854), ('act', 251), ('exemplar', 9240), ('demonstrate', 6696), ('apply', 1386), ('regard', 22748), ('recent', 22512), ('panko', 19706), ('state', 25803), ('development', 6952), ('testing', 27192), ('appear', 1361), ('promise', 21601), ('area', 1512), ('pursue', 21943), ('particular', 19853), ('interest', 13525), ('gap', 10610), ('publish', 21880), ('record', 22590), ('technique', 27013), ('reduce', 22658), ('topic', 27629), ('cross', 5806), ('checking', 4103), ('constraint', 5280), ('effect', 8195), ('aspect', 1690), ('developer', 6951), ('perception', 20131), ('subgraph', 26164), ('isomorphism', 13945), ('problem', 21473), ('ask', 1674), ('host', 12143), ('graph', 11171), ('vertex', 29318), ('contain', 5311), ('isomorphic', 13943), ('restriction', 23220), ('planar', 20638), ('consider', 5239), ('sequence', 24507)]\n"
     ]
    }
   ],
   "source": [
    "print(list(tfidf.vocabulary_.items())[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2c46a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {v:k for k,v in tfidf.vocabulary_.items()}\n",
    "assert len(index_to_word) == len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ef20f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'develop'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word[6947]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f3cdc",
   "metadata": {},
   "source": [
    "### Example of applying to an article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "773a04ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15b259fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs.CY\n",
      "\n",
      "\n",
      "  An undergraduate compilers course poses significant challenges to students,\n",
      "in both the conceptual richness of the major components and in the programming\n",
      "effort necessary to implement them. In this paper, I argue that a related\n",
      "architecture, the interpreter, serves as an effective conceptual framework in\n",
      "which to teach some of the later stages of the compiler pipeline. This\n",
      "framework can serve both to unify some of the major concepts that are taught in\n",
      "a typical undergraduate course and to structure the implementation of a\n",
      "semester-long compiler project.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"categories\"][example_index])\n",
    "print(\"\\n\")\n",
    "print(train_df[\"abstract\"][example_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "632f7d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = train_df[\"tokens\"][example_index] # some article\n",
    "article_vector = tfidf.transform([article])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60684b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "shape:  (1, 30460)\n"
     ]
    }
   ],
   "source": [
    "print(\"type: \", type(article_vector))\n",
    "print(\"shape: \", article_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e8f494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x30460 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 35 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dea34d",
   "metadata": {},
   "source": [
    "### This is a sparse data representation.\n",
    "#### You can see the dense values by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "336b97ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13126994, 0.29570113, 0.12414162, 0.25573269, 0.09767782,\n",
       "       0.07352975, 0.10870997, 0.08726139, 0.2191345 , 0.1669463 ,\n",
       "       0.1711446 , 0.12042176, 0.09975909, 0.09404713, 0.1238445 ,\n",
       "       0.14296485, 0.04324594, 0.10256871, 0.19951817, 0.08924309,\n",
       "       0.13408423, 0.19531875, 0.09101789, 0.08631657, 0.13817846,\n",
       "       0.10256871, 0.08840448, 0.21621191, 0.23270206, 0.08195492,\n",
       "       0.09487108, 0.54319258, 0.07692218, 0.09996748, 0.09404713])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_vector.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67f47211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x30460 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 35 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c04de36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28628, 28484, 28216, 26998, 26089, 26074, 25742, 24832, 24540,\n",
       "       24405, 23430, 22848, 21573, 21562, 20999, 20584, 19716, 17859,\n",
       "       15765, 15445, 14808, 13607, 12802, 12796, 10312,  8216,  8196,\n",
       "        5634,  5035,  5030,  4944,  4910,  4024,  1528,  1497],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_vector.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08c56734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['unify', 0.13126994119063212],\n",
       " ['undergraduate', 0.29570113267907233],\n",
       " ['typical', 0.12414162425578093],\n",
       " ['teach', 0.2557326933891453],\n",
       " ['student', 0.09767782219634011],\n",
       " ['structure', 0.07352974842061219],\n",
       " ['stage', 0.10870997160999991],\n",
       " ['significant', 0.08726139349328559],\n",
       " ['serve', 0.21913449578781913],\n",
       " ['semester', 0.16694629809063208],\n",
       " ['richness', 0.1711445981212223],\n",
       " ['related', 0.12042175704688958],\n",
       " ['project', 0.09975908682955043],\n",
       " ['programming', 0.09404712938450525],\n",
       " ['pose', 0.12384449885892768],\n",
       " ['pipeline', 0.14296484514872537],\n",
       " ['paper', 0.04324594305320362],\n",
       " ['necessary', 0.10256871274372505],\n",
       " ['major', 0.19951817365910085],\n",
       " ['long', 0.08924308614722334],\n",
       " ['later', 0.13408423424641575],\n",
       " ['interpreter', 0.1953187459011147],\n",
       " ['implementation', 0.09101788829155769],\n",
       " ['implement', 0.0863165676758837],\n",
       " ['framework', 0.13817846317370835],\n",
       " ['effort', 0.10256871274372505],\n",
       " ['effective', 0.0884044789507167],\n",
       " ['course', 0.21621190549759856],\n",
       " ['conceptual', 0.23270206037787375],\n",
       " ['concept', 0.08195492154869362],\n",
       " ['component', 0.09487107770602746],\n",
       " ['compiler', 0.5431925781566211],\n",
       " ['challenge', 0.07692217971259273],\n",
       " ['argue', 0.09996747647588855],\n",
       " ['architecture', 0.09404712938450525]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_words = [[index_to_word[feature_index],  article_vector.data[i]]\n",
    "                  for i, feature_index in enumerate(article_vector.indices)]\n",
    "article_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8aa00",
   "metadata": {},
   "source": [
    "### Replicating everything above with core functions on the entire train_df corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f76b5671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core_tfid is a <class 'sklearn.feature_extraction.text.TfidfVectorizer'> \n",
      " with a vocabulary of 30460 words\n"
     ]
    }
   ],
   "source": [
    "#fit the tfid object\n",
    "train_tokens = train_df['tokens']\n",
    "core_tfid, index_to_word = fit_tfid(train_df['tokens'])\n",
    "print(f'core_tfid is a {type(core_tfid)} \\n with a vocabulary of {len(index_to_word)} words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb0eaf",
   "metadata": {},
   "source": [
    "index_to_word is a dict that maps an index number to every unique token in the corpora we fit on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e3982eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'develop'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random index\n",
    "index_to_word[6947]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e10a8b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_matrix, core_index_to_doc = transform_tfid(train_df,tfidf_obj=core_tfid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "892f311d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12432x30460 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 773819 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6b3a5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TF-IDF matrix has dimensions: (12432, 30460)\n"
     ]
    }
   ],
   "source": [
    "print(f'The TF-IDF matrix has dimensions: {core_matrix.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e585f",
   "metadata": {},
   "source": [
    "core_index_to_doc is a dict that maps tfidf matrix row indices to document ids from train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f241edf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1412.0426'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#at random pick row 140 in sparse matrix\n",
    "core_index_to_doc[140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f479b662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>update_dt</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>full_df_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1412.0426</td>\n",
       "      <td>John H. E. Lasseter</td>\n",
       "      <td>The Interpreter In An Undergraduate Compilers Course</td>\n",
       "      <td>cs.CY</td>\n",
       "      <td>An undergraduate compilers course poses significant challenges to students,\\nin both the conceptual richness of the major components and in the programming\\neffort necessary to implement them. In this paper, I argue that a related\\narchitecture, the interpreter, serves as an effective conceptual framework in\\nwhich to teach some of the later stages of the compiler pipeline. This\\nframework can serve both to unify some of the major concepts that are taught in\\na typical undergraduate course and to structure the implementation of a\\nsemester-long compiler project.\\n</td>\n",
       "      <td>2014-12-02</td>\n",
       "      <td>an undergraduate compilers course poses significant challenges to students in both the conceptual richness of the major components and in the programming effort necessary to implement them in this paper i argue that a related architecture the interpreter serves as an effective conceptual framework in which to teach some of the later stages of the compiler pipeline this framework can serve both to unify some of the major concepts that are taught in a typical undergraduate course and to structure the implementation of a semester long compiler project</td>\n",
       "      <td>[undergraduate, compiler, course, pose, significant, challenge, student, conceptual, richness, major, component, programming, effort, necessary, implement, paper, argue, related, architecture, interpreter, serve, effective, conceptual, framework, teach, later, stage, compiler, pipeline, framework, serve, unify, major, concept, teach, typical, undergraduate, course, structure, implementation, semester, long, compiler, project]</td>\n",
       "      <td>4483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id              authors  \\\n",
       "140  1412.0426  John H. E. Lasseter   \n",
       "\n",
       "                                                    title categories  \\\n",
       "140  The Interpreter In An Undergraduate Compilers Course      cs.CY   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         abstract  \\\n",
       "140    An undergraduate compilers course poses significant challenges to students,\\nin both the conceptual richness of the major components and in the programming\\neffort necessary to implement them. In this paper, I argue that a related\\narchitecture, the interpreter, serves as an effective conceptual framework in\\nwhich to teach some of the later stages of the compiler pipeline. This\\nframework can serve both to unify some of the major concepts that are taught in\\na typical undergraduate course and to structure the implementation of a\\nsemester-long compiler project.\\n   \n",
       "\n",
       "      update_dt  \\\n",
       "140  2014-12-02   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          clean  \\\n",
       "140  an undergraduate compilers course poses significant challenges to students in both the conceptual richness of the major components and in the programming effort necessary to implement them in this paper i argue that a related architecture the interpreter serves as an effective conceptual framework in which to teach some of the later stages of the compiler pipeline this framework can serve both to unify some of the major concepts that are taught in a typical undergraduate course and to structure the implementation of a semester long compiler project   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                            tokens  \\\n",
       "140  [undergraduate, compiler, course, pose, significant, challenge, student, conceptual, richness, major, component, programming, effort, necessary, implement, paper, argue, related, architecture, interpreter, serve, effective, conceptual, framework, teach, later, stage, compiler, pipeline, framework, serve, unify, major, concept, teach, typical, undergraduate, course, structure, implementation, semester, long, compiler, project]   \n",
       "\n",
       "     full_df_index  \n",
       "140           4483  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_doc_id = core_index_to_doc[140]\n",
    "train_df[train_df['id'] == single_doc_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0d67c4",
   "metadata": {},
   "source": [
    "We can get the dense values for this row with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "244a725a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13126994, 0.29570113, 0.12414162, 0.25573269, 0.09767782,\n",
       "       0.07352975, 0.10870997, 0.08726139, 0.2191345 , 0.1669463 ,\n",
       "       0.1711446 , 0.12042176, 0.09975909, 0.09404713, 0.1238445 ,\n",
       "       0.14296485, 0.04324594, 0.10256871, 0.19951817, 0.08924309,\n",
       "       0.13408423, 0.19531875, 0.09101789, 0.08631657, 0.13817846,\n",
       "       0.10256871, 0.08840448, 0.21621191, 0.23270206, 0.08195492,\n",
       "       0.09487108, 0.54319258, 0.07692218, 0.09996748, 0.09404713])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_doc = core_matrix.getrow(140)\n",
    "single_doc.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd18ad2f",
   "metadata": {},
   "source": [
    "And the indices of these dense values with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f7bcf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28628, 28484, 28216, 26998, 26089, 26074, 25742, 24832, 24540,\n",
       "       24405, 23430, 22848, 21573, 21562, 20999, 20584, 19716, 17859,\n",
       "       15765, 15445, 14808, 13607, 12802, 12796, 10312,  8216,  8196,\n",
       "        5634,  5035,  5030,  4944,  4910,  4024,  1528,  1497],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_doc.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b59fcc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['unify', 0.13126994119063212],\n",
       " ['undergraduate', 0.29570113267907233],\n",
       " ['typical', 0.12414162425578093],\n",
       " ['teach', 0.2557326933891453],\n",
       " ['student', 0.09767782219634011],\n",
       " ['structure', 0.07352974842061219],\n",
       " ['stage', 0.10870997160999991],\n",
       " ['significant', 0.08726139349328559],\n",
       " ['serve', 0.21913449578781913],\n",
       " ['semester', 0.16694629809063208],\n",
       " ['richness', 0.1711445981212223],\n",
       " ['related', 0.12042175704688958],\n",
       " ['project', 0.09975908682955043],\n",
       " ['programming', 0.09404712938450525],\n",
       " ['pose', 0.12384449885892768],\n",
       " ['pipeline', 0.14296484514872537],\n",
       " ['paper', 0.04324594305320362],\n",
       " ['necessary', 0.10256871274372505],\n",
       " ['major', 0.19951817365910085],\n",
       " ['long', 0.08924308614722334],\n",
       " ['later', 0.13408423424641575],\n",
       " ['interpreter', 0.1953187459011147],\n",
       " ['implementation', 0.09101788829155769],\n",
       " ['implement', 0.0863165676758837],\n",
       " ['framework', 0.13817846317370835],\n",
       " ['effort', 0.10256871274372505],\n",
       " ['effective', 0.0884044789507167],\n",
       " ['course', 0.21621190549759856],\n",
       " ['conceptual', 0.23270206037787375],\n",
       " ['concept', 0.08195492154869362],\n",
       " ['component', 0.09487107770602746],\n",
       " ['compiler', 0.5431925781566211],\n",
       " ['challenge', 0.07692217971259273],\n",
       " ['argue', 0.09996747647588855],\n",
       " ['architecture', 0.09404712938450525]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_doc_words = [[index_to_word[feature_index],  single_doc.data[i]]\n",
    "                    for i, feature_index in enumerate(single_doc.indices)]\n",
    "single_doc_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd10111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO use ,toarray() method to convert to dense matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
